import os
import sys
import json
import torch
import pandas as pd
from torchvision import transforms
from tqdm import tqdm
from PIL import Image, ImageFile
import numpy as np
from model import get_model
import time

ImageFile.LOAD_TRUNCATED_IMAGES = True


def setup_device():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'ä½¿ç”¨è®¾å¤‡: {device}')
    return device


def robust_image_loader(img_path):
    """æç®€å›¾åƒåŠ è½½å‡½æ•°"""
    try:
        image = Image.open(img_path).convert('RGB')
        return image
    except Exception as e:
        print(f"å›¾åƒåŠ è½½å¤±è´¥ {os.path.basename(img_path)}: {e}")
        # å¿«é€Ÿåˆ›å»ºå¤‡ç”¨å›¾åƒ
        return Image.new('RGB', (300, 300), color='gray')


class FastPredictor:

    # ===================================================================
    # åœ¨ class FastPredictor: å†…éƒ¨æ·»åŠ æ­¤æ–¹æ³•
    # ===================================================================

    def predict_batch_all_probs(self, images_batch, use_tta=False, fast_tta=False):
        """
        Streamlit ä¸“ç”¨ï¼šé¢„æµ‹ä¸€ä¸ªæ‰¹æ¬¡å›¾åƒï¼Œè¿”å›æ‰€æœ‰ç±»åˆ«çš„ Softmax æ¦‚ç‡ (NumPyæ•°ç»„)ã€‚
        """
        self.model.eval()

        # 1. TTAå¤„ç†
        if use_tta:
            # é€‰æ‹©TTAç­–ç•¥
            tta_transforms = self.tta_transforms_fast if fast_tta else self.tta_transforms_full
            all_logits = []

            with torch.no_grad():
                for img in images_batch:
                    # å¯¹æ¯ä¸ª TTA å˜æ¢åº”ç”¨
                    # å°† PIL Image è½¬æ¢ä¸º Tensor åˆ—è¡¨
                    img_tensors = [t(img) for t in tta_transforms]
                    img_tensors = torch.stack(img_tensors).to(self.device)

                    # è·å– logit è¾“å‡º
                    outputs = self.model(img_tensors)

                    # å¹³å‡ logit (è€Œä¸æ˜¯æ¦‚ç‡ï¼Œæé«˜å‡†ç¡®ç‡)
                    avg_logit = outputs.mean(dim=0, keepdim=True)
                    all_logits.append(avg_logit)

            logits = torch.cat(all_logits, dim=0)

        # 2. é TTA æ¨¡å¼
        else:
            # ä½¿ç”¨åŸºç¡€ transform å‡†å¤‡ Tensor æ‰¹æ¬¡
            images_tensor = torch.stack([self.transform(img) for img in images_batch]).to(self.device)
            with torch.no_grad():
                logits = self.model(images_tensor)

        # 3. æ¸©åº¦ç¼©æ”¾å’Œ Softmax
        # åº”ç”¨æ¸©åº¦ç¼©æ”¾
        scaled_logits = logits / self.temperature

        # Softmax å¾—åˆ°æ¦‚ç‡
        probabilities = self.softmax(scaled_logits)

        # è¿”å› CPU ä¸Šçš„ numpy æ•°ç»„
        return probabilities.cpu().numpy()


    def __init__(self, config_path, model_path, device, temperature=0.7):
        """åˆå§‹åŒ–å¿«é€Ÿé¢„æµ‹å™¨ - æ·»åŠ æ¸©åº¦ç¼©æ”¾"""
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        self.label_mapping = config['label_mapping']
        self.num_classes = config['num_classes']
        self.reverse_mapping = {int(v): int(k) for k, v in self.label_mapping.items()}
        self.device = device
        self.temperature = temperature  # æ¸©åº¦ç¼©æ”¾å‚æ•°

        # åŠ è½½æ¨¡å‹ - å…¼å®¹æ—§æ¨¡å‹ç»“æ„
        try:
            # å°è¯•åŠ è½½æ–°æ¨¡å‹ç»“æ„
            self.model = get_model(self.num_classes, pretrained=False)
            self.model.load_state_dict(torch.load(model_path, map_location=device))
            print("åŠ è½½æ–°æ¨¡å‹ç»“æ„æˆåŠŸ")
        except RuntimeError as e:
            if "size mismatch" in str(e) or "Missing key" in str(e):
                print("æ£€æµ‹åˆ°æ—§æ¨¡å‹ç»“æ„ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼...")
                # ä½¿ç”¨æ—§æ¨¡å‹ç»“æ„
                self.model = self._get_old_model(self.num_classes)
                self.model.load_state_dict(torch.load(model_path, map_location=device))
                print("å…¼å®¹æ¨¡å¼åŠ è½½æˆåŠŸ")
            else:
                raise e

        self.model = self.model.to(device)
        self.model.eval()

        # åŸºç¡€é¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize(320),
            transforms.CenterCrop(300),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # TTAå¢å¼ºé¢„å¤„ç† - å¯é…ç½®ç‰ˆæœ¬
        self.tta_transforms_full = [
            # åŸå§‹å›¾åƒ
            transforms.Compose([
                transforms.Resize(320),
                transforms.CenterCrop(300),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ]),
            # æ°´å¹³ç¿»è½¬
            transforms.Compose([
                transforms.Resize(320),
                transforms.CenterCrop(300),
                transforms.RandomHorizontalFlip(p=1.0),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ]),
            # å¤šå°ºåº¦1
            transforms.Compose([
                transforms.Resize(340),
                transforms.CenterCrop(300),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ]),
            # å¤šå°ºåº¦2
            transforms.Compose([
                transforms.Resize(310),
                transforms.CenterCrop(300),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        ]

        # å¿«é€ŸTTA - åªç”¨æœ€æœ‰æ•ˆçš„2ç§
        self.tta_transforms_fast = [
            # åŸå§‹å›¾åƒ
            transforms.Compose([
                transforms.Resize(320),
                transforms.CenterCrop(300),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ]),
            # æ°´å¹³ç¿»è½¬
            transforms.Compose([
                transforms.Resize(320),
                transforms.CenterCrop(300),
                transforms.RandomHorizontalFlip(p=1.0),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        ]

        self.softmax = torch.nn.Softmax(dim=1)

        print(f"å¿«é€Ÿé¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ - æ¸©åº¦ç¼©æ”¾: {temperature}")

    def _get_old_model(self, num_classes):
        """æ—§æ¨¡å‹ç»“æ„ - å…¼å®¹å·²è®­ç»ƒçš„æ¨¡å‹"""
        return get_model(num_classes, pretrained=False, version='v1')

    def predict_batch(self, image_batch, use_tta=True, fast_tta=False):
        """æ‰¹é‡é¢„æµ‹ - åº”ç”¨æ¸©åº¦ç¼©æ”¾å’ŒTTA"""
        with torch.no_grad():
            if use_tta:
                # é€‰æ‹©TTAç­–ç•¥
                tta_transforms = self.tta_transforms_fast if fast_tta else self.tta_transforms_full
                all_probs = []

                for transform in tta_transforms:
                    images_tensor = torch.stack([transform(img) for img in image_batch]).to(self.device)
                    outputs = self.model(images_tensor)
                    scaled_outputs = outputs / self.temperature
                    probs = self.softmax(scaled_outputs)
                    all_probs.append(probs)

                # å¹³å‡æ‰€æœ‰TTAç»“æœ
                avg_probs = torch.mean(torch.stack(all_probs), dim=0)
                confs, preds = torch.max(avg_probs, 1)

            else:
                # æ ‡å‡†é¢„æµ‹
                images_tensor = torch.stack([self.transform(img) for img in image_batch]).to(self.device)
                outputs = self.model(images_tensor)
                scaled_outputs = outputs / self.temperature
                probs = self.softmax(scaled_outputs)
                confs, preds = torch.max(probs, 1)

            return preds.cpu().numpy(), confs.cpu().numpy()


def predict_fast(test_dir, output_path, batch_size=32, temperature=0.7, use_tta=True, fast_tta=True,
                 auto_optimize=True):
    """é«˜æ€§èƒ½é¢„æµ‹å‡½æ•° - é’ˆå¯¹å¤§è§„æ¨¡é¢„æµ‹ä¼˜åŒ–"""
    # è·¯å¾„è®¾ç½®
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    config_path = os.path.join(project_root, 'model', 'config.json')
    model_path = os.path.join(project_root, 'model', 'best_model.pth')

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(config_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {config_path}")
        sys.exit(1)
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        sys.exit(1)

    # è®¾ç½®è®¾å¤‡
    device = setup_device()

    # å†…å­˜ä¼˜åŒ–æ£€æŸ¥
    if auto_optimize:
        if batch_size > 32:
            print(f"ğŸ”§ å†…å­˜ä¼˜åŒ–: 16Gå†…å­˜å»ºè®®batch_sizeâ‰¤32ï¼Œå½“å‰{batch_size}å¯èƒ½å¯¼è‡´OOM")
            if batch_size > 64:
                print(f"è‡ªåŠ¨è°ƒæ•´: batch_size {batch_size} â†’ 32")
                batch_size = 32

    # åˆå§‹åŒ–é¢„æµ‹å™¨ - ä¼ å…¥æ¸©åº¦å‚æ•°
    predictor = FastPredictor(config_path, model_path, device, temperature=temperature)

    # å¿«é€Ÿæ‰«æå›¾åƒæ–‡ä»¶
    print("æ‰«æå›¾åƒæ–‡ä»¶ä¸­...")
    supported_formats = ('.jpg', '.jpeg', '.png')
    test_images = []

    for f in os.listdir(test_dir):
        if f.lower().endswith(supported_formats):
            test_images.append(f)

    test_images.sort()
    total_images = len(test_images)
    print(f"æ‰¾åˆ° {total_images} ä¸ªæµ‹è¯•å›¾åƒ")

    if total_images == 0:
        print("é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•å›¾åƒ")
        sys.exit(1)

    # é¢„æµ‹è¿›åº¦ä¼°ç®— - æ›´å‡†ç¡®çš„æ—¶é—´è®¡ç®—
    if use_tta:
        time_per_image = 0.04 if fast_tta else 0.08  # å¿«é€ŸTTA vs å®Œæ•´TTA
        tta_info = "å¿«é€ŸTTA" if fast_tta else "å®Œæ•´TTA"
    else:
        time_per_image = 0.02
        tta_info = "æ— TTA"

    estimated_time = total_images * time_per_image
    print(f"é¢„è®¡å¤„ç†æ—¶é—´({tta_info}): {estimated_time:.1f}ç§’ ({estimated_time / 60:.1f}åˆ†é’Ÿ)")

    # è‡ªåŠ¨ä¼˜åŒ–å¤§è§„æ¨¡é¢„æµ‹
    if auto_optimize and estimated_time > 600:  # 10åˆ†é’Ÿ
        print(f"âš è­¦å‘Š: é¢„è®¡æ—¶é—´è¶…è¿‡10åˆ†é’Ÿ")
        if use_tta and not fast_tta:
            print(f"è‡ªåŠ¨ä¼˜åŒ–: åˆ‡æ¢åˆ°å¿«é€ŸTTAæ¨¡å¼")
            fast_tta = True
            estimated_time = total_images * 0.04
            print(f"ä¼˜åŒ–åé¢„è®¡æ—¶é—´: {estimated_time:.1f}ç§’ ({estimated_time / 60:.1f}åˆ†é’Ÿ)")
        elif use_tta and fast_tta and total_images > 8000:
            print(f"è‡ªåŠ¨ä¼˜åŒ–: å›¾ç‰‡æ•°é‡è¿‡å¤š({total_images}å¼ )ï¼Œå…³é—­TTAä»¥ç¡®ä¿åœ¨æ—¶é—´é™åˆ¶å†…å®Œæˆ")
            use_tta = False
            estimated_time = total_images * 0.02
            print(f"ä¼˜åŒ–åé¢„è®¡æ—¶é—´: {estimated_time:.1f}ç§’ ({estimated_time / 60:.1f}åˆ†é’Ÿ)")
    elif estimated_time > 600:
        print(f"âš è­¦å‘Š: é¢„è®¡æ—¶é—´è¶…è¿‡10åˆ†é’Ÿï¼Œå»ºè®®ä½¿ç”¨å¿«é€ŸTTAæˆ–å…³é—­TTA")
        if not fast_tta and use_tta:
            print(f"å»ºè®®: å½“å‰å®Œæ•´TTAæ¨¡å¼ï¼Œåˆ‡æ¢åˆ°å¿«é€ŸTTAå¯èŠ‚çœ50%æ—¶é—´")

    # æ‰¹é‡é¢„æµ‹
    predictions = []
    processed_count = 0
    batch_count = (total_images + batch_size - 1) // batch_size

    print(f"å¼€å§‹æ‰¹é‡é¢„æµ‹ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}, æ€»æ‰¹æ¬¡: {batch_count}")

    start_time = time.time()

    for batch_start in tqdm(range(0, total_images, batch_size), desc='æ‰¹é‡é¢„æµ‹'):
        batch_end = min(batch_start + batch_size, total_images)
        batch_files = test_images[batch_start:batch_end]

        # åŠ è½½æ‰¹æ¬¡å›¾åƒ
        batch_images = []
        valid_files = []

        for img_name in batch_files:
            try:
                img_path = os.path.join(test_dir, img_name)
                image = robust_image_loader(img_path)
                batch_images.append(image)
                valid_files.append(img_name)
            except Exception as e:
                print(f"è·³è¿‡å›¾åƒ {img_name}: {e}")
                continue

        if not batch_images:
            continue

        # æ‰¹é‡é¢„æµ‹ - å¯ç”¨TTA
        try:
            batch_preds, batch_confs = predictor.predict_batch(batch_images, use_tta=use_tta, fast_tta=fast_tta)

            # å¤„ç†é¢„æµ‹ç»“æœ
            for img_name, pred_idx, confidence in zip(valid_files, batch_preds, batch_confs):
                pred_class = predictor.reverse_mapping[pred_idx]
                predictions.append({
                    'img_name': img_name,
                    'predicted_class': pred_class,
                    'confidence': round(confidence, 4)
                })

            processed_count += len(valid_files)

        except Exception as e:
            print(f"æ‰¹æ¬¡é¢„æµ‹å¤±è´¥: {e}")
            # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡æ·»åŠ é»˜è®¤é¢„æµ‹
            for img_name in valid_files:
                predictions.append({
                    'img_name': img_name,
                    'predicted_class': list(predictor.reverse_mapping.values())[0],
                    'confidence': 0.0
                })

        # å®šæœŸæ¸…ç†GPUå†…å­˜
        if device.type == 'cuda' and batch_start % (batch_size * 10) == 0:
            torch.cuda.empty_cache()

    # æœ€ç»ˆå†…å­˜æ¸…ç†
    if device.type == 'cuda':
        torch.cuda.empty_cache()

    end_time = time.time()
    total_time = end_time - start_time

    # ä¿å­˜ç»“æœ
    print("ä¿å­˜é¢„æµ‹ç»“æœ...")
    df = pd.DataFrame(predictions)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ - æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
    if not os.path.isabs(output_path):
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼ˆcodeçš„ä¸Šçº§ç›®å½•ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(current_dir)
        output_path = os.path.join(project_root, output_path)

    output_dir = os.path.dirname(output_path)
    if output_dir:  # å¦‚æœæœ‰ç›®å½•éƒ¨åˆ†
        os.makedirs(output_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {output_dir}")

    df.to_csv(output_path, index=False, encoding='utf-8')

    # ç»Ÿè®¡ä¿¡æ¯
    valid_predictions = [p for p in predictions if p['confidence'] > 0]
    if valid_predictions:
        confidences = [p['confidence'] for p in valid_predictions]
        avg_confidence = np.mean(confidences)
        max_confidence = max(confidences)
        min_confidence = min(confidences)

        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        high_conf = len([c for c in confidences if c >= 0.9])
        medium_conf = len([c for c in confidences if 0.7 <= c < 0.9])
        low_conf = len([c for c in confidences if c < 0.7])
    else:
        avg_confidence = 0
        max_confidence = 0
        min_confidence = 0
        high_conf = medium_conf = low_conf = 0

    print(f"\né¢„æµ‹å®Œæˆ!")
    print(f"æ€»å¤„ç†å›¾åƒ: {processed_count}/{total_images}")
    print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"å¹³å‡é€Ÿåº¦: {total_images / total_time:.1f} å›¾åƒ/ç§’")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}")
    print(f"ç½®ä¿¡åº¦èŒƒå›´: {min_confidence:.4f} - {max_confidence:.4f}")
    print(f"é«˜ç½®ä¿¡åº¦(â‰¥0.9): {high_conf} ({high_conf / len(confidences) * 100:.1f}%)")
    print(f"ä¸­ç½®ä¿¡åº¦(0.7-0.9): {medium_conf} ({medium_conf / len(confidences) * 100:.1f}%)")
    print(f"ä½ç½®ä¿¡åº¦(<0.7): {low_conf} ({low_conf / len(confidences) * 100:.1f}%)")
    print(f"ç»“æœæ–‡ä»¶: {output_path}")
    print(f"ä½¿ç”¨æ¸©åº¦å‚æ•°: {temperature}")
    print(f"TTAæ¨¡å¼: {'å¿«é€ŸTTA(2x)' if fast_tta else 'å®Œæ•´TTA(4x)' if use_tta else 'æ— TTA'}")

    # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœ
    print(f"\nå‰5ä¸ªé¢„æµ‹ç»“æœ:")
    print(df.head().to_string(index=False))

    return df


def predict(test_dir, output_path, batch_size=32, temperature=0.7, use_tta=True, fast_tta=True):
    """ä¸»é¢„æµ‹å‡½æ•° - å…¼å®¹åŸæœ‰æ¥å£"""
    return predict_fast(test_dir, output_path, batch_size, temperature, use_tta, fast_tta)


if __name__ == '__main__':
    # å‘½ä»¤è¡Œå‚æ•°å¤„ç†
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python predict.py '/path/to/test_images' 'results/submission.csv' [æ‰¹æ¬¡å¤§å°] [æ¸©åº¦å‚æ•°]")
        print("ç¤ºä¾‹: python predict.py '/path/to/test_images' 'results/submission.csv' 32 0.7")
        print("æ³¨æ„: è¾“å‡ºè·¯å¾„ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼ˆcodeæ–‡ä»¶å¤¹çš„ä¸Šçº§ç›®å½•ï¼‰")
        print("æ¸©åº¦å‚æ•°è¯´æ˜: <1.0 æé«˜ç½®ä¿¡åº¦, >1.0 é™ä½ç½®ä¿¡åº¦")
        print("16Gå†…å­˜å»ºè®®batch_size: 16-32")
        sys.exit(1)

    test_dir = sys.argv[1]
    output_path = sys.argv[2]
    batch_size = int(sys.argv[3]) if len(sys.argv) > 3 else 32  # 16Gå†…å­˜å‹å¥½çš„é»˜è®¤å€¼
    temperature = float(sys.argv[4]) if len(sys.argv) > 4 else 0.7

    # éªŒè¯è¾“å…¥ç›®å½•
    if not os.path.exists(test_dir):
        print(f"é”™è¯¯: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨ {test_dir}")
        sys.exit(1)

    print(f"æµ‹è¯•é›†ç›®å½•: {test_dir}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"æ¸©åº¦å‚æ•°: {temperature}")

    # æ‰§è¡Œå¿«é€Ÿé¢„æµ‹ - å¯ç”¨å¿«é€ŸTTAï¼ˆ10åˆ†é’Ÿå†…å®Œæˆï¼‰
    predict_fast(test_dir, output_path, batch_size, temperature, use_tta=True, fast_tta=True)